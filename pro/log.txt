2020-05-11 12:19:42,634 - train_eval - INFO - USING MODEL: bert
2020-05-11 12:19:42,634 - train_eval - INFO - Batch_Size: 32, Using FL: False, Using DISCR: False, Using STLR: False
             precision    recall  f1-score   support

          0     0.8966    0.8966    0.8966        29
          1     1.0000    0.3333    0.5000         3
          2     0.9610    0.9610    0.9610        77
          3     0.0000    0.0000    0.0000         1
          4     0.8958    0.9348    0.9149        46
          5     0.0000    0.0000    0.0000         1
          6     1.0000    0.3333    0.5000         3
          7     0.5000    0.4667    0.4828        15
          8     0.8438    0.6750    0.7500        40
          9     0.9114    0.9474    0.9290        76
         10     0.7500    0.7500    0.7500         4
         11     0.5000    0.2143    0.3000        14
         12     0.6186    0.8391    0.7122        87
         13     0.5000    0.2500    0.3333         4
         15     0.8172    0.8098    0.8135       447
         16     1.0000    1.0000    1.0000         3
         17     0.0000    0.0000    0.0000         6
         18     0.9189    0.8947    0.9067        38
         20     1.0000    1.0000    1.0000         1
         21     1.0000    1.0000    1.0000         2
         22     0.8333    1.0000    0.9091         5
         24     0.7455    0.8817    0.8079        93
         25     0.9375    0.9375    0.9375        16
         26     0.0000    0.0000    0.0000         2
         28     0.7043    0.7289    0.7164       402
         29     0.0000    0.0000    0.0000         1
         30     1.0000    0.3333    0.5000         6
         31     0.0000    0.0000    0.0000         2
         32     0.7500    0.6000    0.6667         5
         33     0.9412    0.6400    0.7619        25
         34     0.7396    0.8659    0.7978        82
         35     0.9326    0.9432    0.9379        88
         36     0.0000    0.0000    0.0000         2
         37     0.8095    0.8500    0.8293        40
         38     0.9273    0.8361    0.8793        61
         40     1.0000    0.2069    0.3429        29
         41     0.9765    0.9432    0.9595        88
         42     1.0000    1.0000    1.0000         4
         43     0.1538    0.2500    0.1905         8
         44     0.2857    0.5000    0.3636         4
         45     0.7863    0.7357    0.7601       140

avg / total     0.7988    0.7940    0.7890      2000

2020-05-11 12:19:42,635 - train_eval - INFO - dev_acc: 0.794  dev_loss: 0.7487971
2020-05-11 12:19:42,635 - train_eval - INFO - -----------------------------------------------------------

2020-05-11 12:36:57,550 - train_eval - INFO - USING MODEL: bert_CNN
2020-05-11 12:36:57,550 - train_eval - INFO - Batch_Size: 32, Using FL: False, Using DISCR: False, Using STLR: False
             precision    recall  f1-score   support

          0     0.8571    0.8276    0.8421        29
          1     0.5000    0.3333    0.4000         3
          2     0.9863    0.9351    0.9600        77
          3     0.0000    0.0000    0.0000         1
          4     0.8302    0.9565    0.8889        46
          5     0.0000    0.0000    0.0000         1
          6     1.0000    0.6667    0.8000         3
          7     0.4375    0.4667    0.4516        15
          8     0.8095    0.8500    0.8293        40
          9     0.9342    0.9342    0.9342        76
         10     0.0000    0.0000    0.0000         4
         11     0.3636    0.2857    0.3200        14
         12     0.6491    0.8506    0.7363        87
         13     0.3333    0.5000    0.4000         4
         15     0.8813    0.7472    0.8087       447
         16     0.5000    0.3333    0.4000         3
         17     0.0000    0.0000    0.0000         6
         18     0.9000    0.9474    0.9231        38
         20     0.0000    0.0000    0.0000         1
         21     0.5000    0.5000    0.5000         2
         22     1.0000    1.0000    1.0000         5
         24     0.7653    0.8065    0.7853        93
         25     0.8824    0.9375    0.9091        16
         26     0.0000    0.0000    0.0000         2
         28     0.6506    0.7736    0.7068       402
         29     0.0000    0.0000    0.0000         1
         30     0.2857    0.3333    0.3077         6
         31     0.0000    0.0000    0.0000         2
         32     1.0000    0.2000    0.3333         5
         33     0.8636    0.7600    0.8085        25
         34     0.7228    0.8902    0.7978        82
         35     0.9610    0.8409    0.8970        88
         36     0.0000    0.0000    0.0000         2
         37     0.8649    0.8000    0.8312        40
         38     0.8621    0.8197    0.8403        61
         40     0.1714    0.2069    0.1875        29
         41     0.9885    0.9773    0.9829        88
         42     0.6667    1.0000    0.8000         4
         43     1.0000    0.2500    0.4000         8
         44     0.0000    0.0000    0.0000         4
         45     0.8390    0.7071    0.7674       140

avg / total     0.7891    0.7805    0.7789      2000

2020-05-11 12:36:57,550 - train_eval - INFO - dev_acc: 0.7805  dev_loss: 0.7232177
2020-05-11 12:36:57,550 - train_eval - INFO - -----------------------------------------------------------

2020-05-11 12:51:13,466 - train_eval - INFO - USING MODEL: bert_DPCNN
2020-05-11 12:51:13,466 - train_eval - INFO - Batch_Size: 32, Using FL: False, Using DISCR: False, Using STLR: False
             precision    recall  f1-score   support

          0     0.8571    0.8276    0.8421        29
          1     0.0000    0.0000    0.0000         3
          2     0.9865    0.9481    0.9669        77
          3     0.0000    0.0000    0.0000         1
          4     0.8431    0.9348    0.8866        46
          5     0.0000    0.0000    0.0000         1
          6     0.0000    0.0000    0.0000         3
          7     0.2000    0.2667    0.2286        15
          8     0.7174    0.8250    0.7674        40
          9     0.9615    0.9868    0.9740        76
         10     0.0000    0.0000    0.0000         4
         11     0.2000    0.0714    0.1053        14
         12     0.6809    0.7356    0.7072        87
         13     1.0000    0.2500    0.4000         4
         15     0.8147    0.8456    0.8299       447
         16     0.0000    0.0000    0.0000         3
         17     0.0000    0.0000    0.0000         6
         18     0.8043    0.9737    0.8810        38
         20     0.0000    0.0000    0.0000         1
         21     0.0000    0.0000    0.0000         2
         22     0.0000    0.0000    0.0000         5
         24     0.6581    0.8280    0.7333        93
         25     0.9375    0.9375    0.9375        16
         26     0.0000    0.0000    0.0000         2
         28     0.7273    0.6766    0.7010       402
         29     0.0000    0.0000    0.0000         1
         30     0.5000    0.1667    0.2500         6
         31     0.0000    0.0000    0.0000         2
         32     0.0000    0.0000    0.0000         5
         33     0.7407    0.8000    0.7692        25
         34     0.7396    0.8659    0.7978        82
         35     0.9222    0.9432    0.9326        88
         36     0.0000    0.0000    0.0000         2
         37     0.8333    0.8750    0.8537        40
         38     0.8667    0.8525    0.8595        61
         40     0.2353    0.2759    0.2540        29
         41     0.9535    0.9318    0.9425        88
         42     1.0000    0.7500    0.8571         4
         43     0.6667    0.2500    0.3636         8
         44     0.0000    0.0000    0.0000         4
         45     0.7589    0.7643    0.7616       140

avg / total     0.7648    0.7805    0.7699      2000

2020-05-11 12:51:13,466 - train_eval - INFO - dev_acc: 0.7805  dev_loss: 0.8207961
2020-05-11 12:51:13,466 - train_eval - INFO - -----------------------------------------------------------

2020-05-11 13:06:10,453 - train_eval - INFO - USING MODEL: bert_lstm
2020-05-11 13:06:10,453 - train_eval - INFO - Batch_Size: 32, Using FL: False, Using DISCR: False, Using STLR: False
             precision    recall  f1-score   support

          0     0.8462    0.7586    0.8000        29
          1     0.0000    0.0000    0.0000         3
          2     0.9733    0.9481    0.9605        77
          3     0.0000    0.0000    0.0000         1
          4     0.8462    0.9565    0.8980        46
          5     0.0000    0.0000    0.0000         1
          6     0.0000    0.0000    0.0000         3
          7     0.0000    0.0000    0.0000        15
          8     0.5323    0.8250    0.6471        40
          9     0.9600    0.9474    0.9536        76
         10     0.0000    0.0000    0.0000         4
         11     0.0000    0.0000    0.0000        14
         12     0.6410    0.8621    0.7353        87
         13     0.0000    0.0000    0.0000         4
         15     0.7778    0.8613    0.8174       447
         16     0.0000    0.0000    0.0000         3
         17     0.0000    0.0000    0.0000         6
         18     0.7872    0.9737    0.8706        38
         20     0.0000    0.0000    0.0000         1
         21     0.0000    0.0000    0.0000         2
         22     0.0000    0.0000    0.0000         5
         24     0.9130    0.6774    0.7778        93
         25     0.8235    0.8750    0.8485        16
         26     0.0000    0.0000    0.0000         2
         28     0.6925    0.7562    0.7229       402
         29     0.0000    0.0000    0.0000         1
         30     0.0000    0.0000    0.0000         6
         31     0.0000    0.0000    0.0000         2
         32     0.0000    0.0000    0.0000         5
         33     0.7500    0.6000    0.6667        25
         34     0.7778    0.7683    0.7730        82
         35     0.9205    0.9205    0.9205        88
         36     0.0000    0.0000    0.0000         2
         37     0.7857    0.8250    0.8049        40
         38     0.8125    0.8525    0.8320        61
         40     1.0000    0.0345    0.0667        29
         41     0.9551    0.9659    0.9605        88
         42     0.0000    0.0000    0.0000         4
         43     0.0000    0.0000    0.0000         8
         44     0.0000    0.0000    0.0000         4
         45     0.7500    0.7500    0.7500       140

avg / total     0.7525    0.7785    0.7556      2000

2020-05-11 13:06:10,453 - train_eval - INFO - dev_acc: 0.7785  dev_loss: 0.8975394
2020-05-11 13:06:10,453 - train_eval - INFO - -----------------------------------------------------------

2020-05-11 13:19:41,740 - train_eval - INFO - USING MODEL: bert_att
2020-05-11 13:19:41,740 - train_eval - INFO - Batch_Size: 32, Using FL: False, Using DISCR: False, Using STLR: False
             precision    recall  f1-score   support

          0     0.8750    0.9655    0.9180        29
          1     1.0000    0.3333    0.5000         3
          2     0.9865    0.9481    0.9669        77
          3     0.0000    0.0000    0.0000         1
          4     0.8980    0.9565    0.9263        46
          5     0.0000    0.0000    0.0000         1
          6     0.6667    0.6667    0.6667         3
          7     0.3529    0.4000    0.3750        15
          8     0.7209    0.7750    0.7470        40
          9     0.9351    0.9474    0.9412        76
         10     0.7500    0.7500    0.7500         4
         11     0.5000    0.2857    0.3636        14
         12     0.6260    0.8851    0.7333        87
         13     0.5000    0.5000    0.5000         4
         15     0.8475    0.7830    0.8140       447
         16     0.7500    1.0000    0.8571         3
         17     0.0000    0.0000    0.0000         6
         18     0.8409    0.9737    0.9024        38
         20     1.0000    1.0000    1.0000         1
         21     1.0000    1.0000    1.0000         2
         22     1.0000    1.0000    1.0000         5
         24     0.8152    0.8065    0.8108        93
         25     1.0000    0.9375    0.9677        16
         26     0.0000    0.0000    0.0000         2
         28     0.7218    0.6841    0.7024       402
         29     0.0000    0.0000    0.0000         1
         30     0.5000    0.3333    0.4000         6
         31     0.0000    0.0000    0.0000         2
         32     0.6667    0.8000    0.7273         5
         33     0.6897    0.8000    0.7407        25
         34     0.7882    0.8171    0.8024        82
         35     0.8842    0.9545    0.9180        88
         36     0.0000    0.0000    0.0000         2
         37     0.7872    0.9250    0.8506        40
         38     0.8462    0.9016    0.8730        61
         40     0.3684    0.2414    0.2917        29
         41     0.8515    0.9773    0.9101        88
         42     1.0000    1.0000    1.0000         4
         43     0.6667    0.2500    0.3636         8
         44     0.4286    0.7500    0.5455         4
         45     0.7730    0.7786    0.7758       140

avg / total     0.7882    0.7930    0.7874      2000

2020-05-11 13:19:41,740 - train_eval - INFO - dev_acc: 0.793  dev_loss: 0.75931287
2020-05-11 13:19:41,740 - train_eval - INFO - -----------------------------------------------------------

2020-05-11 13:33:38,278 - train_eval - INFO - USING MODEL: capsule_net
2020-05-11 13:33:38,279 - train_eval - INFO - Batch_Size: 32, Using FL: False, Using DISCR: False, Using STLR: False
             precision    recall  f1-score   support

          0     0.8889    0.8276    0.8571        29
          1     0.0000    0.0000    0.0000         3
          2     0.9865    0.9481    0.9669        77
          3     0.0000    0.0000    0.0000         1
          4     0.8824    0.9783    0.9278        46
          5     0.0000    0.0000    0.0000         1
          6     0.0000    0.0000    0.0000         3
          7     0.6250    0.3333    0.4348        15
          8     0.7805    0.8000    0.7901        40
          9     0.9600    0.9474    0.9536        76
         10     0.3333    0.2500    0.2857         4
         11     0.0000    0.0000    0.0000        14
         12     0.6786    0.8736    0.7638        87
         13     1.0000    0.2500    0.4000         4
         15     0.7988    0.8613    0.8288       447
         16     0.0000    0.0000    0.0000         3
         17     0.0000    0.0000    0.0000         6
         18     0.9024    0.9737    0.9367        38
         20     0.0000    0.0000    0.0000         1
         21     0.0000    0.0000    0.0000         2
         22     0.0000    0.0000    0.0000         5
         24     0.7822    0.8495    0.8144        93
         25     0.8824    0.9375    0.9091        16
         26     0.0000    0.0000    0.0000         2
         28     0.7559    0.6393    0.6927       402
         29     0.0000    0.0000    0.0000         1
         30     0.0000    0.0000    0.0000         6
         31     0.0000    0.0000    0.0000         2
         32     0.0000    0.0000    0.0000         5
         33     0.6667    0.8800    0.7586        25
         34     0.7374    0.8902    0.8066        82
         35     0.9535    0.9318    0.9425        88
         36     0.0000    0.0000    0.0000         2
         37     0.8537    0.8750    0.8642        40
         38     0.8154    0.8689    0.8413        61
         40     0.1892    0.2414    0.2121        29
         41     0.9438    0.9545    0.9492        88
         42     1.0000    0.7500    0.8571         4
         43     0.0000    0.0000    0.0000         8
         44     0.0000    0.0000    0.0000         4
         45     0.6705    0.8286    0.7412       140

avg / total     0.7668    0.7885    0.7737      2000

2020-05-11 13:33:38,279 - train_eval - INFO - dev_acc: 0.7885  dev_loss: 0.98558533
2020-05-11 13:33:38,279 - train_eval - INFO - -----------------------------------------------------------

2020-05-11 13:45:48,757 - train_eval - INFO - USING MODEL: bert, Using PTM: chinese_rbtl3_pytorch
2020-05-11 13:45:48,757 - train_eval - INFO - Batch_Size: 64, Using FL: False, Using DISCR: False, Using STLR: False
             precision    recall  f1-score   support

          0     0.9286    0.8966    0.9123        29
          1     1.0000    0.3333    0.5000         3
          2     0.9867    0.9610    0.9737        77
          3     1.0000    1.0000    1.0000         1
          4     0.8800    0.9565    0.9167        46
          5     0.0000    0.0000    0.0000         1
          6     0.7500    1.0000    0.8571         3
          7     0.6154    0.5333    0.5714        15
          8     0.7292    0.8750    0.7955        40
          9     0.9012    0.9605    0.9299        76
         10     1.0000    0.7500    0.8571         4
         11     0.5714    0.2857    0.3810        14
         12     0.6700    0.7701    0.7166        87
         13     0.3333    0.2500    0.2857         4
         15     0.8017    0.8322    0.8167       447
         16     1.0000    1.0000    1.0000         3
         17     0.2500    0.1667    0.2000         6
         18     0.9474    0.9474    0.9474        38
         20     1.0000    1.0000    1.0000         1
         21     1.0000    1.0000    1.0000         2
         22     0.8333    1.0000    0.9091         5
         24     0.8261    0.8172    0.8216        93
         25     0.9375    0.9375    0.9375        16
         26     0.5000    0.5000    0.5000         2
         28     0.7339    0.6517    0.6904       402
         29     0.0000    0.0000    0.0000         1
         30     0.5000    0.5000    0.5000         6
         31     1.0000    0.5000    0.6667         2
         32     0.8000    0.8000    0.8000         5
         33     0.6897    0.8000    0.7407        25
         34     0.7742    0.8780    0.8229        82
         35     0.8842    0.9545    0.9180        88
         36     0.3333    0.5000    0.4000         2
         37     0.8444    0.9500    0.8941        40
         38     0.9259    0.8197    0.8696        61
         40     0.2632    0.1724    0.2083        29
         41     0.9663    0.9773    0.9718        88
         42     1.0000    1.0000    1.0000         4
         43     0.6667    0.5000    0.5714         8
         44     0.6000    0.7500    0.6667         4
         45     0.7746    0.7857    0.7801       140

avg / total     0.7967    0.7995    0.7957      2000

2020-05-11 13:45:48,757 - train_eval - INFO - dev_acc: 0.7995  dev_loss: 0.9459765
2020-05-11 13:45:48,757 - train_eval - INFO - -----------------------------------------------------------

2020-05-11 14:22:14,959 - train_eval - INFO - USING MODEL: bert_DPCNN, Using PTM: chinese_rbtl3_pytorch
2020-05-11 14:22:14,959 - train_eval - INFO - Batch_Size: 64, Using FL: False, Using DISCR: False, Using STLR: False
             precision    recall  f1-score   support

          0     0.9615    0.8621    0.9091        29
          1     1.0000    0.3333    0.5000         3
          2     0.9730    0.9351    0.9536        77
          3     0.5000    1.0000    0.6667         1
          4     0.9111    0.8913    0.9011        46
          5     0.0000    0.0000    0.0000         1
          6     0.7500    1.0000    0.8571         3
          7     0.5263    0.6667    0.5882        15
          8     0.9032    0.7000    0.7887        40
          9     0.9467    0.9342    0.9404        76
         10     1.0000    0.5000    0.6667         4
         11     0.3000    0.2143    0.2500        14
         12     0.7340    0.7931    0.7624        87
         13     1.0000    0.2500    0.4000         4
         15     0.8246    0.8412    0.8328       447
         16     1.0000    1.0000    1.0000         3
         17     0.0000    0.0000    0.0000         6
         18     0.9024    0.9737    0.9367        38
         20     0.0000    0.0000    0.0000         1
         21     1.0000    1.0000    1.0000         2
         22     0.8333    1.0000    0.9091         5
         24     0.7935    0.7849    0.7892        93
         25     1.0000    0.9375    0.9677        16
         26     1.0000    0.5000    0.6667         2
         28     0.6829    0.7338    0.7074       402
         29     0.0000    0.0000    0.0000         1
         30     0.4286    0.5000    0.4615         6
         31     0.5000    0.5000    0.5000         2
         32     0.6667    0.8000    0.7273         5
         33     0.8500    0.6800    0.7556        25
         34     0.8462    0.6707    0.7483        82
         35     0.9111    0.9318    0.9213        88
         36     0.0000    0.0000    0.0000         2
         37     0.8261    0.9500    0.8837        40
         38     0.8929    0.8197    0.8547        61
         40     0.3125    0.3448    0.3279        29
         41     0.9651    0.9432    0.9540        88
         42     1.0000    1.0000    1.0000         4
         43     0.5556    0.6250    0.5882         8
         44     0.4444    1.0000    0.6154         4
         45     0.7803    0.7357    0.7574       140

avg / total     0.7998    0.7965    0.7954      2000

2020-05-11 14:22:14,959 - train_eval - INFO - dev_acc: 0.7965  dev_loss: 1.0600009
2020-05-11 14:22:14,959 - train_eval - INFO - -----------------------------------------------------------

2020-05-11 14:35:45,416 - train_eval - INFO - USING MODEL: bert_lstm, Using PTM: chinese_rbtl3_pytorch
2020-05-11 14:35:45,416 - train_eval - INFO - Batch_Size: 64, Using FL: False, Using DISCR: False, Using STLR: False
             precision    recall  f1-score   support

          0     0.9231    0.8276    0.8727        29
          1     1.0000    0.3333    0.5000         3
          2     0.9610    0.9610    0.9610        77
          3     0.0000    0.0000    0.0000         1
          4     0.8600    0.9348    0.8958        46
          5     0.0000    0.0000    0.0000         1
          6     1.0000    1.0000    1.0000         3
          7     0.5500    0.7333    0.6286        15
          8     0.7955    0.8750    0.8333        40
          9     0.9103    0.9342    0.9221        76
         10     0.5000    0.5000    0.5000         4
         11     0.4286    0.2143    0.2857        14
         12     0.7340    0.7931    0.7624        87
         13     0.6667    0.5000    0.5714         4
         15     0.8079    0.8658    0.8359       447
         16     1.0000    0.6667    0.8000         3
         17     0.0000    0.0000    0.0000         6
         18     0.8837    1.0000    0.9383        38
         20     0.0000    0.0000    0.0000         1
         21     1.0000    1.0000    1.0000         2
         22     0.8333    1.0000    0.9091         5
         24     0.7248    0.8495    0.7822        93
         25     1.0000    0.9375    0.9677        16
         26     0.0000    0.0000    0.0000         2
         28     0.6880    0.6965    0.6922       402
         29     0.0000    0.0000    0.0000         1
         30     0.4000    0.3333    0.3636         6
         31     0.0000    0.0000    0.0000         2
         32     0.6667    0.4000    0.5000         5
         33     0.7500    0.8400    0.7925        25
         34     0.8696    0.7317    0.7947        82
         35     0.8925    0.9432    0.9171        88
         36     0.0000    0.0000    0.0000         2
         37     0.8500    0.8500    0.8500        40
         38     0.8730    0.9016    0.8871        61
         40     0.3333    0.2069    0.2553        29
         41     0.9770    0.9659    0.9714        88
         42     1.0000    1.0000    1.0000         4
         43     1.0000    0.2500    0.4000         8
         44     0.5000    0.2500    0.3333         4
         45     0.8087    0.6643    0.7294       140

avg / total     0.7892    0.7970    0.7896      2000

2020-05-11 14:35:45,416 - train_eval - INFO - dev_acc: 0.797  dev_loss: 0.84258324
2020-05-11 14:35:45,416 - train_eval - INFO - -----------------------------------------------------------

2020-05-11 14:46:20,341 - train_eval - INFO - USING MODEL: bert_att, Using PTM: chinese_rbtl3_pytorch
2020-05-11 14:46:20,341 - train_eval - INFO - Batch_Size: 64, Using FL: False, Using DISCR: False, Using STLR: False
             precision    recall  f1-score   support

          0     0.9630    0.8966    0.9286        29
          1     1.0000    0.3333    0.5000         3
          2     0.9610    0.9610    0.9610        77
          3     0.5000    1.0000    0.6667         1
          4     0.8750    0.9130    0.8936        46
          5     0.0000    0.0000    0.0000         1
          6     0.7500    1.0000    0.8571         3
          7     0.6000    0.6000    0.6000        15
          8     0.7907    0.8500    0.8193        40
          9     0.9467    0.9342    0.9404        76
         10     1.0000    1.0000    1.0000         4
         11     0.5000    0.2857    0.3636        14
         12     0.7368    0.8046    0.7692        87
         13     1.0000    0.5000    0.6667         4
         15     0.7822    0.8434    0.8116       447
         16     1.0000    1.0000    1.0000         3
         17     0.3333    0.1667    0.2222         6
         18     0.8636    1.0000    0.9268        38
         20     1.0000    1.0000    1.0000         1
         21     1.0000    1.0000    1.0000         2
         22     1.0000    1.0000    1.0000         5
         24     0.7273    0.8602    0.7882        93
         25     1.0000    1.0000    1.0000        16
         26     1.0000    0.5000    0.6667         2
         28     0.7466    0.6741    0.7085       402
         29     0.0000    0.0000    0.0000         1
         30     0.2500    0.3333    0.2857         6
         31     1.0000    0.5000    0.6667         2
         32     1.0000    0.6000    0.7500         5
         33     0.8889    0.6400    0.7442        25
         34     0.7952    0.8049    0.8000        82
         35     0.9121    0.9432    0.9274        88
         36     0.5000    0.5000    0.5000         2
         37     0.8500    0.8500    0.8500        40
         38     0.9123    0.8525    0.8814        61
         40     0.2500    0.2759    0.2623        29
         41     0.9560    0.9886    0.9721        88
         42     1.0000    1.0000    1.0000         4
         43     1.0000    0.3750    0.5455         8
         44     0.6667    0.5000    0.5714         4
         45     0.7820    0.7429    0.7619       140

avg / total     0.8016    0.8010    0.7982      2000

2020-05-11 14:46:20,342 - train_eval - INFO - dev_acc: 0.801  dev_loss: 1.0064192
2020-05-11 14:46:20,342 - train_eval - INFO - -----------------------------------------------------------

2020-05-11 16:10:32,580 - train_eval - INFO - USING MODEL: bert_CNN, Using PTM: chinese_rbtl3_pytorch
2020-05-11 16:10:32,580 - train_eval - INFO - Batch_Size: 64, Using FL: False, Using DISCR: False, Using STLR: False
             precision    recall  f1-score   support

          0     0.9630    0.8966    0.9286        29
          1     1.0000    0.3333    0.5000         3
          2     0.9367    0.9610    0.9487        77
          3     0.5000    1.0000    0.6667         1
          4     0.9130    0.9130    0.9130        46
          5     0.0000    0.0000    0.0000         1
          6     1.0000    1.0000    1.0000         3
          7     0.8182    0.6000    0.6923        15
          8     0.8684    0.8250    0.8462        40
          9     0.9351    0.9474    0.9412        76
         10     1.0000    0.7500    0.8571         4
         11     0.5000    0.2143    0.3000        14
         12     0.6731    0.8046    0.7330        87
         13     0.5000    0.2500    0.3333         4
         15     0.8176    0.8121    0.8148       447
         16     1.0000    1.0000    1.0000         3
         17     0.0000    0.0000    0.0000         6
         18     0.9459    0.9211    0.9333        38
         20     1.0000    1.0000    1.0000         1
         21     1.0000    1.0000    1.0000         2
         22     1.0000    1.0000    1.0000         5
         24     0.7426    0.8065    0.7732        93
         25     1.0000    0.9375    0.9677        16
         26     0.5000    0.5000    0.5000         2
         28     0.6566    0.7562    0.7029       402
         29     0.0000    0.0000    0.0000         1
         30     0.6667    0.3333    0.4444         6
         31     1.0000    0.5000    0.6667         2
         32     1.0000    0.6000    0.7500         5
         33     0.8947    0.6800    0.7727        25
         34     0.7917    0.6951    0.7403        82
         35     0.9643    0.9205    0.9419        88
         36     0.5000    0.5000    0.5000         2
         37     0.8571    0.9000    0.8780        40
         38     0.9259    0.8197    0.8696        61
         40     0.3333    0.1034    0.1579        29
         41     0.9247    0.9773    0.9503        88
         42     1.0000    1.0000    1.0000         4
         43     0.6667    0.2500    0.3636         8
         44     0.4286    0.7500    0.5455         4
         45     0.7557    0.7071    0.7306       140

avg / total     0.7917    0.7935    0.7883      2000

2020-05-11 16:10:32,580 - train_eval - INFO - dev_acc: 0.7935  dev_loss: 1.0341866
2020-05-11 16:10:32,580 - train_eval - INFO - -----------------------------------------------------------

2020-05-11 16:33:56,724 - train_eval - INFO - USING MODEL: capsule_net, Using PTM: chinese_rbtl3_pytorch
2020-05-11 16:33:56,724 - train_eval - INFO - Batch_Size: 64, Using FL: False, Using DISCR: False, Using STLR: False
             precision    recall  f1-score   support

          0     0.8889    0.8276    0.8571        29
          1     1.0000    0.3333    0.5000         3
          2     0.9605    0.9481    0.9542        77
          3     0.0000    0.0000    0.0000         1
          4     0.9130    0.9130    0.9130        46
          5     0.0000    0.0000    0.0000         1
          6     0.7500    1.0000    0.8571         3
          7     0.6000    0.4000    0.4800        15
          8     0.7674    0.8250    0.7952        40
          9     0.9125    0.9605    0.9359        76
         10     1.0000    0.7500    0.8571         4
         11     0.4286    0.2143    0.2857        14
         12     0.6931    0.8046    0.7447        87
         13     0.5000    0.2500    0.3333         4
         15     0.7680    0.8814    0.8208       447
         16     1.0000    1.0000    1.0000         3
         17     0.0000    0.0000    0.0000         6
         18     0.9000    0.9474    0.9231        38
         20     1.0000    1.0000    1.0000         1
         21     1.0000    1.0000    1.0000         2
         22     1.0000    1.0000    1.0000         5
         24     0.7957    0.7957    0.7957        93
         25     1.0000    0.9375    0.9677        16
         26     0.3333    0.5000    0.4000         2
         28     0.7239    0.6393    0.6790       402
         29     0.0000    0.0000    0.0000         1
         30     0.6667    0.3333    0.4444         6
         31     0.0000    0.0000    0.0000         2
         32     0.7500    0.6000    0.6667         5
         33     0.7500    0.8400    0.7925        25
         34     0.8481    0.8171    0.8323        82
         35     0.8925    0.9432    0.9171        88
         36     0.0000    0.0000    0.0000         2
         37     0.8095    0.8500    0.8293        40
         38     0.8833    0.8689    0.8760        61
         40     0.3846    0.1724    0.2381        29
         41     0.9556    0.9773    0.9663        88
         42     1.0000    0.7500    0.8571         4
         43     0.5000    0.2500    0.3333         8
         44     0.8000    1.0000    0.8889         4
         45     0.7222    0.7429    0.7324       140

avg / total     0.7835    0.7935    0.7849      2000

2020-05-11 16:33:56,724 - train_eval - INFO - dev_acc: 0.7935  dev_loss: 0.95734036
2020-05-11 16:33:56,725 - train_eval - INFO - -----------------------------------------------------------



2020-05-11 17:15:08,836 - train_eval - INFO - USING MODEL: bert, Using PTM: chinese_rbtl3_pytorch
2020-05-11 17:15:08,836 - train_eval - INFO - Batch_Size: 64, Using FL: True, Using DISCR: False, Using STLR: False
             precision    recall  f1-score   support

          0     0.9286    0.8966    0.9123        29
          1     1.0000    0.3333    0.5000         3
          2     0.9487    0.9610    0.9548        77
          3     1.0000    1.0000    1.0000         1
          4     0.8800    0.9565    0.9167        46
          5     0.0000    0.0000    0.0000         1
          6     0.7500    1.0000    0.8571         3
          7     0.7273    0.5333    0.6154        15
          8     0.7556    0.8500    0.8000        40
          9     0.8916    0.9737    0.9308        76
         10     1.0000    0.7500    0.8571         4
         11     0.5000    0.2143    0.3000        14
         12     0.6765    0.7931    0.7302        87
         13     0.3333    0.2500    0.2857         4
         15     0.8112    0.8456    0.8280       447
         16     1.0000    1.0000    1.0000         3
         17     0.5000    0.1667    0.2500         6
         18     0.9231    0.9474    0.9351        38
         20     1.0000    1.0000    1.0000         1
         21     1.0000    1.0000    1.0000         2
         22     1.0000    1.0000    1.0000         5
         24     0.8280    0.8280    0.8280        93
         25     0.9375    0.9375    0.9375        16
         26     0.5000    0.5000    0.5000         2
         28     0.7278    0.6517    0.6877       402
         29     0.0000    0.0000    0.0000         1
         30     0.3333    0.3333    0.3333         6
         31     1.0000    0.5000    0.6667         2
         32     0.8000    0.8000    0.8000         5
         33     0.8261    0.7600    0.7917        25
         34     0.8000    0.8780    0.8372        82
         35     0.8673    0.9659    0.9140        88
         36     0.5000    0.5000    0.5000         2
         37     0.8043    0.9250    0.8605        40
         38     0.9444    0.8361    0.8870        61
         40     0.3500    0.2414    0.2857        29
         41     0.9545    0.9545    0.9545        88
         42     1.0000    1.0000    1.0000         4
         43     0.6667    0.7500    0.7059         8
         44     0.6000    0.7500    0.6667         4
         45     0.7817    0.7929    0.7872       140

avg / total     0.8004    0.8045    0.7998      2000

2020-05-11 17:15:08,836 - train_eval - INFO - dev_acc: 0.8045  dev_loss: 0.5031412
2020-05-11 17:15:08,836 - train_eval - INFO - -----------------------------------------------------------

2020-05-11 17:28:08,986 - train_eval - INFO - USING MODEL: bert_CNN, Using PTM: chinese_rbtl3_pytorch
2020-05-11 17:28:08,986 - train_eval - INFO - Batch_Size: 64, Using FL: True, Using DISCR: False, Using STLR: False
             precision    recall  f1-score   support

          0     0.9286    0.8966    0.9123        29
          1     1.0000    0.3333    0.5000         3
          2     0.9250    0.9610    0.9427        77
          3     1.0000    1.0000    1.0000         1
          4     0.9130    0.9130    0.9130        46
          5     0.0000    0.0000    0.0000         1
          6     1.0000    1.0000    1.0000         3
          7     0.6667    0.5333    0.5926        15
          8     0.8095    0.8500    0.8293        40
          9     0.9231    0.9474    0.9351        76
         10     1.0000    0.5000    0.6667         4
         11     0.6000    0.2143    0.3158        14
         12     0.7216    0.8046    0.7609        87
         13     0.6667    0.5000    0.5714         4
         15     0.7987    0.8523    0.8247       447
         16     1.0000    1.0000    1.0000         3
         17     0.3333    0.1667    0.2222         6
         18     0.9250    0.9737    0.9487        38
         20     1.0000    1.0000    1.0000         1
         21     0.6667    1.0000    0.8000         2
         22     1.0000    1.0000    1.0000         5
         24     0.7957    0.7957    0.7957        93
         25     1.0000    0.9375    0.9677        16
         26     0.5000    0.5000    0.5000         2
         28     0.7065    0.7065    0.7065       402
         29     0.0000    0.0000    0.0000         1
         30     0.6667    0.3333    0.4444         6
         31     1.0000    0.5000    0.6667         2
         32     1.0000    0.8000    0.8889         5
         33     0.7917    0.7600    0.7755        25
         34     0.8000    0.7317    0.7643        82
         35     0.9432    0.9432    0.9432        88
         36     0.5000    0.5000    0.5000         2
         37     0.8444    0.9500    0.8941        40
         38     0.9444    0.8361    0.8870        61
         40     0.5000    0.1724    0.2564        29
         41     0.9247    0.9773    0.9503        88
         42     1.0000    1.0000    1.0000         4
         43     0.5714    0.5000    0.5333         8
         44     0.3333    0.7500    0.4615         4
         45     0.7664    0.7500    0.7581       140

avg / total     0.8010    0.8040    0.7990      2000

2020-05-11 17:28:08,986 - train_eval - INFO - dev_acc: 0.804  dev_loss: 0.52408695
2020-05-11 17:28:08,986 - train_eval - INFO - -----------------------------------------------------------

2020-05-11 18:03:04,817 - train_eval - INFO - USING MODEL: bert_lstm, Using PTM: chinese_rbtl3_pytorch
2020-05-11 18:03:04,817 - train_eval - INFO - Batch_Size: 64, Using FL: True, Using DISCR: False, Using STLR: False
             precision    recall  f1-score   support

          0     0.9600    0.8276    0.8889        29
          1     1.0000    0.3333    0.5000         3
          2     0.9733    0.9481    0.9605        77
          3     1.0000    1.0000    1.0000         1
          4     0.8958    0.9348    0.9149        46
          5     0.0000    0.0000    0.0000         1
          6     1.0000    1.0000    1.0000         3
          7     0.5000    0.6667    0.5714        15
          8     0.8140    0.8750    0.8434        40
          9     0.9091    0.9211    0.9150        76
         10     1.0000    0.5000    0.6667         4
         11     0.4286    0.2143    0.2857        14
         12     0.6944    0.8621    0.7692        87
         13     0.5000    0.5000    0.5000         4
         15     0.8081    0.8479    0.8275       447
         16     1.0000    1.0000    1.0000         3
         17     0.0000    0.0000    0.0000         6
         18     0.9250    0.9737    0.9487        38
         20     1.0000    1.0000    1.0000         1
         21     1.0000    1.0000    1.0000         2
         22     0.8333    1.0000    0.9091         5
         24     0.7938    0.8280    0.8105        93
         25     1.0000    0.9375    0.9677        16
         26     0.5000    0.5000    0.5000         2
         28     0.6843    0.7065    0.6952       402
         29     0.0000    0.0000    0.0000         1
         30     0.5000    0.3333    0.4000         6
         31     0.0000    0.0000    0.0000         2
         32     0.6667    0.4000    0.5000         5
         33     0.8000    0.8000    0.8000        25
         34     0.8493    0.7561    0.8000        82
         35     0.8925    0.9432    0.9171        88
         36     0.0000    0.0000    0.0000         2
         37     0.8333    0.8750    0.8537        40
         38     0.8750    0.9180    0.8960        61
         40     0.2105    0.1379    0.1667        29
         41     0.9770    0.9659    0.9714        88
         42     1.0000    1.0000    1.0000         4
         43     0.5000    0.2500    0.3333         8
         44     0.3333    0.2500    0.2857         4
         45     0.8407    0.6786    0.7510       140

avg / total     0.7927    0.7985    0.7929      2000

2020-05-11 18:03:04,817 - train_eval - INFO - dev_acc: 0.7985  dev_loss: 0.48178893
2020-05-11 18:03:04,817 - train_eval - INFO - -----------------------------------------------------------

2020-05-11 18:13:42,711 - train_eval - INFO - USING MODEL: bert_att, Using PTM: chinese_rbtl3_pytorch
2020-05-11 18:13:42,711 - train_eval - INFO - Batch_Size: 64, Using FL: True, Using DISCR: False, Using STLR: False
             precision    recall  f1-score   support

          0     0.8966    0.8966    0.8966        29
          1     1.0000    0.3333    0.5000         3
          2     0.9487    0.9610    0.9548        77
          3     1.0000    1.0000    1.0000         1
          4     0.8600    0.9348    0.8958        46
          5     0.0000    0.0000    0.0000         1
          6     0.7500    1.0000    0.8571         3
          7     0.5556    0.6667    0.6061        15
          8     0.7609    0.8750    0.8140        40
          9     0.9467    0.9342    0.9404        76
         10     1.0000    0.7500    0.8571         4
         11     0.4444    0.2857    0.3478        14
         12     0.6939    0.7816    0.7351        87
         13     1.0000    0.5000    0.6667         4
         15     0.7909    0.8210    0.8057       447
         16     1.0000    1.0000    1.0000         3
         17     0.3333    0.1667    0.2222         6
         18     0.8605    0.9737    0.9136        38
         20     1.0000    1.0000    1.0000         1
         21     1.0000    1.0000    1.0000         2
         22     1.0000    1.0000    1.0000         5
         23     0.0000    0.0000    0.0000         0
         24     0.7333    0.8280    0.7778        93
         25     1.0000    0.9375    0.9677        16
         26     0.5000    0.5000    0.5000         2
         28     0.7197    0.6642    0.6908       402
         29     0.0000    0.0000    0.0000         1
         30     0.3333    0.3333    0.3333         6
         31     1.0000    0.5000    0.6667         2
         32     1.0000    0.6000    0.7500         5
         33     0.8889    0.6400    0.7442        25
         34     0.7711    0.7805    0.7758        82
         35     0.8925    0.9432    0.9171        88
         36     0.5000    0.5000    0.5000         2
         37     0.8919    0.8250    0.8571        40
         38     0.9107    0.8361    0.8718        61
         40     0.2308    0.2069    0.2182        29
         41     0.9149    0.9773    0.9451        88
         42     1.0000    1.0000    1.0000         4
         43     0.6667    0.2500    0.3636         8
         44     0.3333    0.2500    0.2857         4
         45     0.7464    0.7357    0.7410       140

avg / total     0.7858    0.7865    0.7837      2000

2020-05-11 18:13:42,712 - train_eval - INFO - dev_acc: 0.7865  dev_loss: 0.51349515
2020-05-11 18:13:42,712 - train_eval - INFO - -----------------------------------------------------------

2020-05-11 18:23:49,921 - train_eval - INFO - USING MODEL: bert, Using PTM: chinese_rbtl3_pytorch
2020-05-11 18:23:49,921 - train_eval - INFO - Batch_Size: 64, Using FL: False, Using DISCR: True, Using STLR: False
             precision    recall  f1-score   support

          0     0.9286    0.8966    0.9123        29
          1     1.0000    0.3333    0.5000         3
          2     0.9867    0.9610    0.9737        77
          3     1.0000    1.0000    1.0000         1
          4     0.8571    0.9130    0.8842        46
          5     0.0000    0.0000    0.0000         1
          6     0.7500    1.0000    0.8571         3
          7     0.6923    0.6000    0.6429        15
          8     0.7727    0.8500    0.8095        40
          9     0.9012    0.9605    0.9299        76
         10     1.0000    0.7500    0.8571         4
         11     0.5714    0.2857    0.3810        14
         12     0.6990    0.8276    0.7579        87
         13     0.3333    0.2500    0.2857         4
         15     0.8226    0.8300    0.8263       447
         16     1.0000    1.0000    1.0000         3
         17     0.3333    0.1667    0.2222         6
         18     0.9474    0.9474    0.9474        38
         20     1.0000    1.0000    1.0000         1
         21     1.0000    1.0000    1.0000         2
         22     0.8333    1.0000    0.9091         5
         24     0.8021    0.8280    0.8148        93
         25     1.0000    0.9375    0.9677        16
         26     0.5000    0.5000    0.5000         2
         28     0.7213    0.6567    0.6875       402
         29     0.0000    0.0000    0.0000         1
         30     0.3333    0.3333    0.3333         6
         31     1.0000    0.5000    0.6667         2
         32     0.8000    0.8000    0.8000         5
         33     0.7000    0.8400    0.7636        25
         34     0.7634    0.8659    0.8114        82
         35     0.8842    0.9545    0.9180        88
         36     0.3333    0.5000    0.4000         2
         37     0.8444    0.9500    0.8941        40
         38     0.8966    0.8525    0.8739        61
         40     0.2778    0.1724    0.2128        29
         41     0.9451    0.9773    0.9609        88
         42     1.0000    1.0000    1.0000         4
         43     0.6000    0.3750    0.4615         8
         44     0.6000    0.7500    0.6667         4
         45     0.7872    0.7929    0.7900       140

avg / total     0.7988    0.8025    0.7984      2000

2020-05-11 18:23:49,921 - train_eval - INFO - dev_acc: 0.8025  dev_loss: 0.9072486
2020-05-11 18:23:49,921 - train_eval - INFO - -----------------------------------------------------------

2020-05-11 18:36:47,555 - train_eval - INFO - USING MODEL: bert_CNN, Using PTM: chinese_rbtl3_pytorch
2020-05-11 18:36:47,555 - train_eval - INFO - Batch_Size: 64, Using FL: False, Using DISCR: True, Using STLR: False
             precision    recall  f1-score   support

          0     0.9630    0.8966    0.9286        29
          1     1.0000    0.3333    0.5000         3
          2     0.9487    0.9610    0.9548        77
          3     0.5000    1.0000    0.6667         1
          4     0.9130    0.9130    0.9130        46
          5     0.0000    0.0000    0.0000         1
          6     1.0000    1.0000    1.0000         3
          7     0.7000    0.4667    0.5600        15
          8     0.8333    0.8750    0.8537        40
          9     0.9600    0.9474    0.9536        76
         10     1.0000    0.7500    0.8571         4
         11     0.5000    0.2143    0.3000        14
         12     0.7234    0.7816    0.7514        87
         13     0.5000    0.2500    0.3333         4
         15     0.8349    0.8143    0.8245       447
         16     1.0000    1.0000    1.0000         3
         17     0.0000    0.0000    0.0000         6
         18     0.9000    0.9474    0.9231        38
         20     1.0000    1.0000    1.0000         1
         21     0.6667    1.0000    0.8000         2
         22     1.0000    1.0000    1.0000         5
         24     0.7353    0.8065    0.7692        93
         25     1.0000    0.9375    0.9677        16
         26     0.5000    0.5000    0.5000         2
         28     0.6772    0.7463    0.7101       402
         29     0.0000    0.0000    0.0000         1
         30     0.6667    0.3333    0.4444         6
         31     1.0000    0.5000    0.6667         2
         32     1.0000    0.6000    0.7500         5
         33     0.7391    0.6800    0.7083        25
         34     0.7831    0.7927    0.7879        82
         35     0.9540    0.9432    0.9486        88
         36     0.3333    0.5000    0.4000         2
         37     0.9000    0.9000    0.9000        40
         38     0.9259    0.8197    0.8696        61
         40     0.3333    0.1724    0.2273        29
         41     0.9556    0.9773    0.9663        88
         42     1.0000    1.0000    1.0000         4
         43     0.5000    0.2500    0.3333         8
         44     0.6667    0.5000    0.5714         4
         45     0.7260    0.7571    0.7413       140

avg / total     0.7972    0.8005    0.7962      2000

2020-05-11 18:36:47,555 - train_eval - INFO - dev_acc: 0.8005  dev_loss: 0.98412836
2020-05-11 18:36:47,555 - train_eval - INFO - -----------------------------------------------------------

2020-05-11 18:50:23,582 - train_eval - INFO - USING MODEL: bert_lstm, Using PTM: chinese_rbtl3_pytorch
2020-05-11 18:50:23,583 - train_eval - INFO - Batch_Size: 64, Using FL: False, Using DISCR: True, Using STLR: False
             precision    recall  f1-score   support

          0     0.9231    0.8276    0.8727        29
          1     1.0000    0.3333    0.5000         3
          2     0.9610    0.9610    0.9610        77
          3     0.0000    0.0000    0.0000         1
          4     0.8750    0.9130    0.8936        46
          5     0.0000    0.0000    0.0000         1
          6     1.0000    0.6667    0.8000         3
          7     0.5000    0.7333    0.5946        15
          8     0.7955    0.8750    0.8333        40
          9     0.9103    0.9342    0.9221        76
         10     0.6667    0.5000    0.5714         4
         11     0.4286    0.2143    0.2857        14
         12     0.6931    0.8046    0.7447        87
         13     0.5000    0.5000    0.5000         4
         15     0.8132    0.8568    0.8344       447
         16     1.0000    0.6667    0.8000         3
         17     0.0000    0.0000    0.0000         6
         18     0.9268    1.0000    0.9620        38
         20     0.0000    0.0000    0.0000         1
         21     1.0000    1.0000    1.0000         2
         22     0.8333    1.0000    0.9091         5
         24     0.7453    0.8495    0.7940        93
         25     1.0000    0.9375    0.9677        16
         26     0.0000    0.0000    0.0000         2
         28     0.6731    0.6965    0.6846       402
         29     0.0000    0.0000    0.0000         1
         30     0.5000    0.3333    0.4000         6
         31     0.0000    0.0000    0.0000         2
         32     1.0000    0.6000    0.7500         5
         33     0.7692    0.8000    0.7843        25
         34     0.8571    0.7317    0.7895        82
         35     0.8925    0.9432    0.9171        88
         36     0.0000    0.0000    0.0000         2
         37     0.8718    0.8500    0.8608        40
         38     0.8462    0.9016    0.8730        61
         40     0.3125    0.1724    0.2222        29
         41     0.9773    0.9773    0.9773        88
         42     1.0000    1.0000    1.0000         4
         43     0.5000    0.2500    0.3333         8
         44     0.5000    0.2500    0.3333         4
         45     0.8142    0.6571    0.7273       140

avg / total     0.7859    0.7940    0.7869      2000

2020-05-11 18:50:23,583 - train_eval - INFO - dev_acc: 0.794  dev_loss: 0.82906693
2020-05-11 18:50:23,583 - train_eval - INFO - -----------------------------------------------------------

2020-05-11 19:01:01,615 - train_eval - INFO - USING MODEL: bert_att, Using PTM: chinese_rbtl3_pytorch
2020-05-11 19:01:01,615 - train_eval - INFO - Batch_Size: 64, Using FL: False, Using DISCR: True, Using STLR: False
             precision    recall  f1-score   support

          0     0.9630    0.8966    0.9286        29
          1     1.0000    0.3333    0.5000         3
          2     1.0000    0.9610    0.9801        77
          3     0.5000    1.0000    0.6667         1
          4     0.8936    0.9130    0.9032        46
          5     0.0000    0.0000    0.0000         1
          6     0.7500    1.0000    0.8571         3
          7     0.6667    0.6667    0.6667        15
          8     0.7907    0.8500    0.8193        40
          9     0.9221    0.9342    0.9281        76
         10     1.0000    1.0000    1.0000         4
         11     0.5714    0.2857    0.3810        14
         12     0.7128    0.7701    0.7403        87
         13     0.6667    0.5000    0.5714         4
         15     0.7632    0.8434    0.8013       447
         16     1.0000    1.0000    1.0000         3
         17     0.3333    0.1667    0.2222         6
         18     0.8605    0.9737    0.9136        38
         20     1.0000    1.0000    1.0000         1
         21     1.0000    1.0000    1.0000         2
         22     1.0000    1.0000    1.0000         5
         23     0.0000    0.0000    0.0000         0
         24     0.7339    0.8602    0.7921        93
         25     1.0000    1.0000    1.0000        16
         26     1.0000    0.5000    0.6667         2
         28     0.7354    0.6567    0.6938       402
         29     0.0000    0.0000    0.0000         1
         30     0.2500    0.3333    0.2857         6
         31     1.0000    0.5000    0.6667         2
         32     1.0000    0.6000    0.7500         5
         33     0.9375    0.6000    0.7317        25
         34     0.7882    0.8171    0.8024        82
         35     0.9121    0.9432    0.9274        88
         36     0.5000    0.5000    0.5000         2
         37     0.8293    0.8500    0.8395        40
         38     0.9455    0.8525    0.8966        61
         40     0.1935    0.2069    0.2000        29
         41     0.9355    0.9886    0.9613        88
         42     1.0000    1.0000    1.0000         4
         43     1.0000    0.3750    0.5455         8
         44     0.5000    0.5000    0.5000         4
         45     0.7953    0.7214    0.7566       140

avg / total     0.7954    0.7935    0.7908      2000

2020-05-11 19:01:01,615 - train_eval - INFO - dev_acc: 0.7935  dev_loss: 0.97732294
2020-05-11 19:01:01,616 - train_eval - INFO - -----------------------------------------------------------

2020-05-11 19:11:08,853 - train_eval - INFO - USING MODEL: bert, Using PTM: chinese_rbtl3_pytorch
2020-05-11 19:11:08,853 - train_eval - INFO - Batch_Size: 64, Using FL: False, Using DISCR: False, Using STLR: True
             precision    recall  f1-score   support

          0     0.8667    0.8966    0.8814        29
          1     1.0000    0.3333    0.5000         3
          2     0.9733    0.9481    0.9605        77
          3     0.0000    0.0000    0.0000         1
          4     0.8627    0.9565    0.9072        46
          5     0.0000    0.0000    0.0000         1
          6     0.7500    1.0000    0.8571         3
          7     0.4706    0.5333    0.5000        15
          8     0.7447    0.8750    0.8046        40
          9     0.9103    0.9342    0.9221        76
         10     0.7500    0.7500    0.7500         4
         11     0.6667    0.2857    0.4000        14
         12     0.7100    0.8161    0.7594        87
         13     1.0000    0.2500    0.4000         4
         15     0.8122    0.8613    0.8360       447
         16     1.0000    0.6667    0.8000         3
         17     0.0000    0.0000    0.0000         6
         18     0.9487    0.9737    0.9610        38
         20     1.0000    1.0000    1.0000         1
         21     1.0000    0.5000    0.6667         2
         22     0.8333    1.0000    0.9091         5
         24     0.8261    0.8172    0.8216        93
         25     1.0000    0.9375    0.9677        16
         26     1.0000    0.5000    0.6667         2
         28     0.7242    0.6990    0.7114       402
         29     0.0000    0.0000    0.0000         1
         30     0.4000    0.3333    0.3636         6
         31     0.0000    0.0000    0.0000         2
         32     1.0000    0.6000    0.7500         5
         33     0.8261    0.7600    0.7917        25
         34     0.8095    0.8293    0.8193        82
         35     0.9130    0.9545    0.9333        88
         36     0.0000    0.0000    0.0000         2
         37     0.8684    0.8250    0.8462        40
         38     0.8667    0.8525    0.8595        61
         40     0.2778    0.1724    0.2128        29
         41     0.9885    0.9773    0.9829        88
         42     1.0000    1.0000    1.0000         4
         43     0.7500    0.3750    0.5000         8
         44     0.6000    0.7500    0.6667         4
         45     0.7622    0.7786    0.7703       140

avg / total     0.8005    0.8075    0.8013      2000

2020-05-11 19:11:08,853 - train_eval - INFO - dev_acc: 0.8075  dev_loss: 0.61869574
2020-05-11 19:11:08,853 - train_eval - INFO - -----------------------------------------------------------

2020-05-11 19:27:04,247 - train_eval - INFO - USING MODEL: bert_CNN, Using PTM: chinese_rbtl3_pytorch
2020-05-11 19:27:04,247 - train_eval - INFO - Batch_Size: 64, Using FL: False, Using DISCR: False, Using STLR: True
             precision    recall  f1-score   support

          0     0.8710    0.9310    0.9000        29
          1     1.0000    0.3333    0.5000         3
          2     0.9865    0.9481    0.9669        77
          3     0.0000    0.0000    0.0000         1
          4     0.8980    0.9565    0.9263        46
          5     0.0000    0.0000    0.0000         1
          6     0.7500    1.0000    0.8571         3
          7     0.5000    0.6667    0.5714        15
          8     0.8500    0.8500    0.8500        40
          9     0.9595    0.9342    0.9467        76
         10     0.7500    0.7500    0.7500         4
         11     0.5000    0.2143    0.3000        14
         12     0.7347    0.8276    0.7784        87
         13     0.5000    0.5000    0.5000         4
         15     0.8221    0.8479    0.8348       447
         16     1.0000    0.6667    0.8000         3
         17     0.0000    0.0000    0.0000         6
         18     0.9024    0.9737    0.9367        38
         20     0.0000    0.0000    0.0000         1
         21     1.0000    1.0000    1.0000         2
         22     0.8333    1.0000    0.9091         5
         24     0.8000    0.8602    0.8290        93
         25     1.0000    0.9375    0.9677        16
         26     0.5000    0.5000    0.5000         2
         28     0.7455    0.7289    0.7371       402
         29     0.0000    0.0000    0.0000         1
         30     0.3333    0.3333    0.3333         6
         31     0.0000    0.0000    0.0000         2
         32     1.0000    0.6000    0.7500         5
         33     0.7143    0.8000    0.7547        25
         34     0.8718    0.8293    0.8500        82
         35     0.9130    0.9545    0.9333        88
         36     0.0000    0.0000    0.0000         2
         37     0.8750    0.8750    0.8750        40
         38     0.9153    0.8852    0.9000        61
         40     0.3333    0.2414    0.2800        29
         41     0.9551    0.9659    0.9605        88
         42     1.0000    1.0000    1.0000         4
         43     0.6667    0.2500    0.3636         8
         44     0.7500    0.7500    0.7500         4
         45     0.7671    0.8000    0.7832       140

avg / total     0.8106    0.8180    0.8124      2000

2020-05-11 19:27:04,248 - train_eval - INFO - dev_acc: 0.818  dev_loss: 0.60374457
2020-05-11 19:27:04,248 - train_eval - INFO - -----------------------------------------------------------

2020-05-11 19:40:37,292 - train_eval - INFO - USING MODEL: bert_lstm, Using PTM: chinese_rbtl3_pytorch
2020-05-11 19:40:37,292 - train_eval - INFO - Batch_Size: 64, Using FL: False, Using DISCR: False, Using STLR: True
             precision    recall  f1-score   support

          0     0.8065    0.8621    0.8333        29
          1     0.0000    0.0000    0.0000         3
          2     0.9737    0.9610    0.9673        77
          3     0.0000    0.0000    0.0000         1
          4     0.8627    0.9565    0.9072        46
          5     0.0000    0.0000    0.0000         1
          6     0.0000    0.0000    0.0000         3
          7     0.0000    0.0000    0.0000        15
          8     0.5690    0.8250    0.6735        40
          9     0.9211    0.9211    0.9211        76
         10     0.0000    0.0000    0.0000         4
         11     0.0000    0.0000    0.0000        14
         12     0.7019    0.8391    0.7644        87
         13     0.0000    0.0000    0.0000         4
         15     0.8112    0.8456    0.8280       447
         16     0.0000    0.0000    0.0000         3
         17     0.0000    0.0000    0.0000         6
         18     0.9024    0.9737    0.9367        38
         20     0.0000    0.0000    0.0000         1
         21     0.0000    0.0000    0.0000         2
         22     0.0000    0.0000    0.0000         5
         24     0.7624    0.8280    0.7938        93
         25     0.9375    0.9375    0.9375        16
         26     0.0000    0.0000    0.0000         2
         28     0.6995    0.7065    0.7030       402
         29     0.0000    0.0000    0.0000         1
         30     1.0000    0.1667    0.2857         6
         31     0.0000    0.0000    0.0000         2
         32     0.0000    0.0000    0.0000         5
         33     0.7241    0.8400    0.7778        25
         34     0.7978    0.8659    0.8304        82
         35     0.8646    0.9432    0.9022        88
         36     0.0000    0.0000    0.0000         2
         37     0.8571    0.9000    0.8780        40
         38     0.8413    0.8689    0.8548        61
         40     0.3333    0.1724    0.2273        29
         41     0.9659    0.9659    0.9659        88
         42     0.0000    0.0000    0.0000         4
         43     0.0000    0.0000    0.0000         8
         44     0.0000    0.0000    0.0000         4
         45     0.7347    0.7714    0.7526       140

avg / total     0.7523    0.7865    0.7669      2000

2020-05-11 19:40:37,292 - train_eval - INFO - dev_acc: 0.7865  dev_loss: 0.7343842
2020-05-11 19:40:37,292 - train_eval - INFO - -----------------------------------------------------------

2020-05-11 19:51:16,099 - train_eval - INFO - USING MODEL: bert_att, Using PTM: chinese_rbtl3_pytorch
2020-05-11 19:51:16,099 - train_eval - INFO - Batch_Size: 64, Using FL: False, Using DISCR: False, Using STLR: True
             precision    recall  f1-score   support

          0     0.9000    0.9310    0.9153        29
          1     1.0000    0.3333    0.5000         3
          2     0.9865    0.9481    0.9669        77
          3     1.0000    1.0000    1.0000         1
          4     0.8600    0.9348    0.8958        46
          5     0.0000    0.0000    0.0000         1
          6     0.7500    1.0000    0.8571         3
          7     0.6429    0.6000    0.6207        15
          8     0.8095    0.8500    0.8293        40
          9     0.9726    0.9342    0.9530        76
         10     1.0000    0.7500    0.8571         4
         11     0.6000    0.2143    0.3158        14
         12     0.7100    0.8161    0.7594        87
         13     0.6667    0.5000    0.5714         4
         15     0.8154    0.8792    0.8461       447
         16     1.0000    1.0000    1.0000         3
         17     0.5000    0.1667    0.2500         6
         18     0.9024    0.9737    0.9367        38
         20     1.0000    1.0000    1.0000         1
         21     1.0000    1.0000    1.0000         2
         22     1.0000    1.0000    1.0000         5
         23     0.0000    0.0000    0.0000         0
         24     0.8462    0.8280    0.8370        93
         25     1.0000    0.9375    0.9677        16
         26     1.0000    0.5000    0.6667         2
         28     0.7467    0.7114    0.7287       402
         29     0.0000    0.0000    0.0000         1
         30     0.2500    0.3333    0.2857         6
         31     0.0000    0.0000    0.0000         2
         32     1.0000    1.0000    1.0000         5
         33     0.7692    0.8000    0.7843        25
         34     0.8256    0.8659    0.8452        82
         35     0.9032    0.9545    0.9282        88
         36     0.0000    0.0000    0.0000         2
         37     0.8537    0.8750    0.8642        40
         38     0.8814    0.8525    0.8667        61
         40     0.4118    0.2414    0.3043        29
         41     0.9773    0.9773    0.9773        88
         42     1.0000    1.0000    1.0000         4
         43     1.0000    0.2500    0.4000         8
         44     0.4286    0.7500    0.5455         4
         45     0.7868    0.7643    0.7754       140

avg / total     0.8165    0.8200    0.8149      2000

2020-05-11 19:51:16,099 - train_eval - INFO - dev_acc: 0.82  dev_loss: 0.6162833
2020-05-11 19:51:16,099 - train_eval - INFO - -----------------------------------------------------------

2020-05-11 20:07:14,720 - train_eval - INFO - USING MODEL: bert, Using PTM: chinese_rbtl3_pytorch
2020-05-11 20:07:14,720 - train_eval - INFO - Batch_Size: 64, Using FL: False, Using DISCR: False, Using STLR: False
             precision    recall  f1-score   support

          0     0.9091    0.8333    0.8696        24
          1     0.0000    0.0000    0.0000         3
          2     0.9750    0.9512    0.9630        82
          3     0.3333    1.0000    0.5000         1
          4     0.8627    0.9565    0.9072        46
          5     0.9231    1.0000    0.9600        12
          6     1.0000    1.0000    1.0000        12
          7     0.6000    0.5294    0.5625        17
          8     0.7632    0.8056    0.7838        36
          9     0.9333    0.9333    0.9333        90
         10     0.5000    1.0000    0.6667         2
         11     0.6667    0.2667    0.3810        15
         12     0.6827    0.8353    0.7513        85
         13     0.7500    1.0000    0.8571         3
         14     1.0000    1.0000    1.0000         4
         15     0.8368    0.8018    0.8189       454
         16     1.0000    1.0000    1.0000        11
         17     0.0000    0.0000    0.0000        10
         18     0.8537    0.9459    0.8974        37
         19     1.0000    1.0000    1.0000         5
         20     1.0000    1.0000    1.0000         8
         21     1.0000    1.0000    1.0000         1
         22     1.0000    1.0000    1.0000         6
         24     0.8556    0.7549    0.8021       102
         25     1.0000    0.9231    0.9600        13
         26     0.0000    0.0000    0.0000         1
         27     1.0000    0.6667    0.8000         3
         28     0.6789    0.7066    0.6925       392
         29     0.0000    0.0000    0.0000         1
         30     0.4000    0.2857    0.3333         7
         31     0.7500    1.0000    0.8571         6
         32     1.0000    0.6000    0.7500         5
         33     0.7568    0.8485    0.8000        33
         34     0.8125    0.7536    0.7820        69
         35     0.9157    0.9870    0.9500        77
         36     1.0000    1.0000    1.0000         6
         37     0.9250    0.8810    0.9024        42
         38     0.8788    0.9062    0.8923        64
         39     1.0000    1.0000    1.0000         7
         40     0.3182    0.2414    0.2745        29
         41     0.9524    0.9639    0.9581        83
         42     1.0000    1.0000    1.0000         4
         43     0.7143    0.8333    0.7692         6
         44     0.5000    0.5000    0.5000         8
         45     0.7329    0.7926    0.7616       135

avg / total     0.7998    0.8036    0.7995      2057

2020-05-11 20:07:14,720 - train_eval - INFO - dev_acc: 0.8035974720466699  dev_loss: 0.8511161
2020-05-11 20:07:14,720 - train_eval - INFO - -----------------------------------------------------------

2020-05-11 20:20:34,954 - train_eval - INFO - USING MODEL: bert_CNN, Using PTM: chinese_rbtl3_pytorch
2020-05-11 20:20:34,954 - train_eval - INFO - Batch_Size: 64, Using FL: False, Using DISCR: False, Using STLR: False
             precision    recall  f1-score   support

          0     0.9091    0.8333    0.8696        24
          1     0.0000    0.0000    0.0000         3
          2     1.0000    0.8780    0.9351        82
          3     0.5000    1.0000    0.6667         1
          4     0.8491    0.9783    0.9091        46
          5     0.9167    0.9167    0.9167        12
          6     1.0000    0.9167    0.9565        12
          7     0.5000    0.3529    0.4138        17
          8     0.6522    0.8333    0.7317        36
          9     1.0000    0.9000    0.9474        90
         10     1.0000    1.0000    1.0000         2
         11     0.5000    0.2667    0.3478        15
         12     0.7471    0.7647    0.7558        85
         13     0.7500    1.0000    0.8571         3
         14     1.0000    1.0000    1.0000         4
         15     0.8244    0.8172    0.8208       454
         16     1.0000    1.0000    1.0000        11
         17     0.0000    0.0000    0.0000        10
         18     0.8780    0.9730    0.9231        37
         19     0.8333    1.0000    0.9091         5
         20     1.0000    1.0000    1.0000         8
         21     1.0000    1.0000    1.0000         1
         22     1.0000    1.0000    1.0000         6
         24     0.8902    0.7157    0.7935       102
         25     1.0000    0.9231    0.9600        13
         26     0.0000    0.0000    0.0000         1
         27     1.0000    0.6667    0.8000         3
         28     0.6570    0.6939    0.6749       392
         29     0.0000    0.0000    0.0000         1
         30     0.3333    0.2857    0.3077         7
         31     0.6667    1.0000    0.8000         6
         32     1.0000    0.6000    0.7500         5
         33     0.6364    0.8485    0.7273        33
         34     0.7403    0.8261    0.7808        69
         35     0.9036    0.9740    0.9375        77
         36     0.8571    1.0000    0.9231         6
         37     0.9250    0.8810    0.9024        42
         38     0.9194    0.8906    0.9048        64
         39     1.0000    1.0000    1.0000         7
         40     0.2963    0.2759    0.2857        29
         41     0.9630    0.9398    0.9512        83
         42     1.0000    1.0000    1.0000         4
         43     0.6667    0.6667    0.6667         6
         44     0.6667    0.2500    0.3636         8
         45     0.7310    0.7852    0.7571       135

avg / total     0.7935    0.7934    0.7907      2057

2020-05-11 20:20:34,954 - train_eval - INFO - dev_acc: 0.7933884297520661  dev_loss: 0.93103594
2020-05-11 20:20:34,954 - train_eval - INFO - -----------------------------------------------------------

2020-05-11 20:34:34,851 - train_eval - INFO - USING MODEL: bert_lstm, Using PTM: chinese_rbtl3_pytorch
2020-05-11 20:34:34,851 - train_eval - INFO - Batch_Size: 64, Using FL: False, Using DISCR: False, Using STLR: False
             precision    recall  f1-score   support

          0     0.9091    0.8333    0.8696        24
          1     0.0000    0.0000    0.0000         3
          2     1.0000    0.9268    0.9620        82
          3     0.5000    1.0000    0.6667         1
          4     0.9167    0.9565    0.9362        46
          5     0.9231    1.0000    0.9600        12
          6     1.0000    1.0000    1.0000        12
          7     0.5714    0.4706    0.5161        17
          8     0.6889    0.8611    0.7654        36
          9     0.9767    0.9333    0.9545        90
         10     1.0000    1.0000    1.0000         2
         11     0.8571    0.4000    0.5455        15
         12     0.7619    0.7529    0.7574        85
         13     0.5000    1.0000    0.6667         3
         14     1.0000    1.0000    1.0000         4
         15     0.7859    0.8568    0.8198       454
         16     1.0000    1.0000    1.0000        11
         17     1.0000    0.1000    0.1818        10
         18     0.9024    1.0000    0.9487        37
         19     1.0000    1.0000    1.0000         5
         20     1.0000    1.0000    1.0000         8
         21     1.0000    1.0000    1.0000         1
         22     1.0000    1.0000    1.0000         6
         24     0.7921    0.7843    0.7882       102
         25     0.9231    0.9231    0.9231        13
         26     0.0000    0.0000    0.0000         1
         27     1.0000    0.6667    0.8000         3
         28     0.6846    0.6811    0.6829       392
         29     0.0000    0.0000    0.0000         1
         30     0.4000    0.2857    0.3333         7
         31     0.7143    0.8333    0.7692         6
         32     1.0000    0.4000    0.5714         5
         33     0.7778    0.8485    0.8116        33
         34     0.8308    0.7826    0.8060        69
         35     0.9146    0.9740    0.9434        77
         36     1.0000    1.0000    1.0000         6
         37     0.9231    0.8571    0.8889        42
         38     0.8308    0.8438    0.8372        64
         39     1.0000    1.0000    1.0000         7
         40     0.5625    0.3103    0.4000        29
         41     0.9877    0.9639    0.9756        83
         42     1.0000    1.0000    1.0000         4
         43     0.5000    0.1667    0.2500         6
         44     0.6000    0.3750    0.4615         8
         45     0.7609    0.7778    0.7692       135

avg / total     0.8049    0.8055    0.8006      2057

2020-05-11 20:34:34,851 - train_eval - INFO - dev_acc: 0.8055420515313564  dev_loss: 0.7806343
2020-05-11 20:34:34,851 - train_eval - INFO - -----------------------------------------------------------

2020-05-11 20:45:26,126 - train_eval - INFO - USING MODEL: bert_att, Using PTM: chinese_rbtl3_pytorch
2020-05-11 20:45:26,126 - train_eval - INFO - Batch_Size: 64, Using FL: False, Using DISCR: False, Using STLR: False
             precision    recall  f1-score   support

          0     0.9091    0.8333    0.8696        24
          1     0.0000    0.0000    0.0000         3
          2     0.9872    0.9390    0.9625        82
          3     0.5000    1.0000    0.6667         1
          4     0.9000    0.9783    0.9375        46
          5     0.9231    1.0000    0.9600        12
          6     1.0000    1.0000    1.0000        12
          7     0.5625    0.5294    0.5455        17
          8     0.6875    0.9167    0.7857        36
          9     0.9247    0.9556    0.9399        90
         10     1.0000    1.0000    1.0000         2
         11     0.6667    0.2667    0.3810        15
         12     0.7882    0.7882    0.7882        85
         13     0.7500    1.0000    0.8571         3
         14     1.0000    1.0000    1.0000         4
         15     0.7854    0.8789    0.8295       454
         16     1.0000    1.0000    1.0000        11
         17     0.7500    0.3000    0.4286        10
         18     0.8537    0.9459    0.8974        37
         19     1.0000    1.0000    1.0000         5
         20     1.0000    1.0000    1.0000         8
         21     1.0000    1.0000    1.0000         1
         22     1.0000    1.0000    1.0000         6
         24     0.8037    0.8431    0.8230       102
         25     1.0000    0.9231    0.9600        13
         26     0.0000    0.0000    0.0000         1
         27     1.0000    0.6667    0.8000         3
         28     0.7680    0.6250    0.6892       392
         29     0.0000    0.0000    0.0000         1
         30     0.3333    0.2857    0.3077         7
         31     0.7500    1.0000    0.8571         6
         32     1.0000    0.6000    0.7500         5
         33     0.7317    0.9091    0.8108        33
         34     0.7714    0.7826    0.7770        69
         35     0.8736    0.9870    0.9268        77
         36     1.0000    1.0000    1.0000         6
         37     0.9231    0.8571    0.8889        42
         38     0.8923    0.9062    0.8992        64
         39     1.0000    1.0000    1.0000         7
         40     0.5294    0.3103    0.3913        29
         41     0.9878    0.9759    0.9818        83
         42     1.0000    1.0000    1.0000         4
         43     1.0000    0.5000    0.6667         6
         44     0.8000    0.5000    0.6154         8
         45     0.7333    0.8148    0.7719       135

avg / total     0.8140    0.8153    0.8096      2057

2020-05-11 20:45:26,126 - train_eval - INFO - dev_acc: 0.8152649489547885  dev_loss: 0.98553586
2020-05-11 20:45:26,126 - train_eval - INFO - -----------------------------------------------------------

2020-05-11 20:55:50,862 - train_eval - INFO - USING MODEL: bert, Using PTM: chinese_rbtl3_pytorch
2020-05-11 20:55:50,863 - train_eval - INFO - Batch_Size: 64, Using FL: True, Using DISCR: True, Using STLR: True
             precision    recall  f1-score   support

          0     0.8696    0.8333    0.8511        24
          1     0.0000    0.0000    0.0000         3
          2     0.9873    0.9512    0.9689        82
          3     0.3333    1.0000    0.5000         1
          4     0.9000    0.9783    0.9375        46
          5     0.9231    1.0000    0.9600        12
          6     0.9231    1.0000    0.9600        12
          7     0.5385    0.4118    0.4667        17
          8     0.7209    0.8611    0.7848        36
          9     0.9765    0.9222    0.9486        90
         10     0.5000    1.0000    0.6667         2
         11     0.8333    0.3333    0.4762        15
         12     0.6765    0.8118    0.7380        85
         13     1.0000    0.6667    0.8000         3
         14     1.0000    1.0000    1.0000         4
         15     0.8293    0.8348    0.8321       454
         16     1.0000    1.0000    1.0000        11
         17     0.6667    0.2000    0.3077        10
         18     0.8780    0.9730    0.9231        37
         19     1.0000    1.0000    1.0000         5
         20     1.0000    1.0000    1.0000         8
         21     1.0000    1.0000    1.0000         1
         22     1.0000    1.0000    1.0000         6
         24     0.8602    0.7843    0.8205       102
         25     1.0000    0.9231    0.9600        13
         26     0.0000    0.0000    0.0000         1
         27     1.0000    0.6667    0.8000         3
         28     0.7221    0.7423    0.7321       392
         29     0.0000    0.0000    0.0000         1
         30     0.4000    0.2857    0.3333         7
         31     0.7500    1.0000    0.8571         6
         32     1.0000    0.4000    0.5714         5
         33     0.8000    0.8485    0.8235        33
         34     0.8451    0.8696    0.8571        69
         35     0.9048    0.9870    0.9441        77
         36     1.0000    1.0000    1.0000         6
         37     0.9487    0.8810    0.9136        42
         38     0.8939    0.9219    0.9077        64
         39     1.0000    1.0000    1.0000         7
         40     0.3889    0.2414    0.2979        29
         41     0.9877    0.9639    0.9756        83
         42     1.0000    1.0000    1.0000         4
         43     0.8000    0.6667    0.7273         6
         44     1.0000    0.5000    0.6667         8
         45     0.7714    0.8000    0.7855       135

avg / total     0.8221    0.8235    0.8193      2057

2020-05-11 20:55:50,863 - train_eval - INFO - dev_acc: 0.8235294117647058  dev_loss: 0.31247756
2020-05-11 20:55:50,863 - train_eval - INFO - -----------------------------------------------------------

2020-05-11 21:09:14,569 - train_eval - INFO - USING MODEL: bert_CNN, Using PTM: chinese_rbtl3_pytorch
2020-05-11 21:09:14,569 - train_eval - INFO - Batch_Size: 64, Using FL: True, Using DISCR: True, Using STLR: True
             precision    recall  f1-score   support

          0     0.8696    0.8333    0.8511        24
          1     0.0000    0.0000    0.0000         3
          2     0.9750    0.9512    0.9630        82
          3     0.5000    1.0000    0.6667         1
          4     0.9184    0.9783    0.9474        46
          5     0.9231    1.0000    0.9600        12
          6     0.9231    1.0000    0.9600        12
          7     0.5000    0.4118    0.4516        17
          8     0.7333    0.9167    0.8148        36
          9     0.9432    0.9222    0.9326        90
         10     1.0000    1.0000    1.0000         2
         11     0.6667    0.2667    0.3810        15
         12     0.7500    0.8118    0.7797        85
         13     0.6000    1.0000    0.7500         3
         14     1.0000    1.0000    1.0000         4
         15     0.8248    0.8502    0.8373       454
         16     1.0000    1.0000    1.0000        11
         17     1.0000    0.1000    0.1818        10
         18     0.8372    0.9730    0.9000        37
         19     1.0000    1.0000    1.0000         5
         20     1.0000    1.0000    1.0000         8
         21     1.0000    1.0000    1.0000         1
         22     1.0000    1.0000    1.0000         6
         24     0.7980    0.7745    0.7861       102
         25     1.0000    1.0000    1.0000        13
         26     0.0000    0.0000    0.0000         1
         27     1.0000    0.6667    0.8000         3
         28     0.7198    0.7143    0.7170       392
         29     0.0000    0.0000    0.0000         1
         30     0.2857    0.2857    0.2857         7
         31     0.8571    1.0000    0.9231         6
         32     1.0000    0.2000    0.3333         5
         33     0.7000    0.8485    0.7671        33
         34     0.8116    0.8116    0.8116        69
         35     0.9157    0.9870    0.9500        77
         36     1.0000    1.0000    1.0000         6
         37     0.9487    0.8810    0.9136        42
         38     0.8939    0.9219    0.9077        64
         39     1.0000    1.0000    1.0000         7
         40     0.4762    0.3448    0.4000        29
         41     0.9877    0.9639    0.9756        83
         42     1.0000    1.0000    1.0000         4
         43     0.3333    0.1667    0.2222         6
         44     0.8000    0.5000    0.6154         8
         45     0.7778    0.7778    0.7778       135

avg / total     0.8158    0.8182    0.8127      2057

2020-05-11 21:09:14,569 - train_eval - INFO - dev_acc: 0.8181818181818182  dev_loss: 0.32108194
2020-05-11 21:09:14,570 - train_eval - INFO - -----------------------------------------------------------

2020-05-11 21:53:09,888 - train_eval - INFO - USING MODEL: bert_lstm, Using PTM: chinese_rbtl3_pytorch
2020-05-11 21:53:09,888 - train_eval - INFO - Batch_Size: 64, Using FL: False, Using DISCR: True, Using STLR: True
             precision    recall  f1-score   support

          0     0.7857    0.9167    0.8462        24
          1     0.0000    0.0000    0.0000         3
          2     0.9753    0.9634    0.9693        82
          3     0.0000    0.0000    0.0000         1
          4     0.9362    0.9565    0.9462        46
          5     0.8750    0.5833    0.7000        12
          6     1.0000    0.9167    0.9565        12
          7     0.0000    0.0000    0.0000        17
          8     0.5079    0.8889    0.6465        36
          9     0.9432    0.9222    0.9326        90
         10     0.0000    0.0000    0.0000         2
         11     0.0000    0.0000    0.0000        15
         12     0.7010    0.8000    0.7473        85
         13     0.0000    0.0000    0.0000         3
         14     0.0000    0.0000    0.0000         4
         15     0.8114    0.8436    0.8272       454
         16     1.0000    0.6364    0.7778        11
         17     0.0000    0.0000    0.0000        10
         18     0.8182    0.9730    0.8889        37
         19     0.0000    0.0000    0.0000         5
         20     0.8889    1.0000    0.9412         8
         21     0.0000    0.0000    0.0000         1
         22     0.0000    0.0000    0.0000         6
         24     0.7544    0.8431    0.7963       102
         25     0.9231    0.9231    0.9231        13
         26     0.0000    0.0000    0.0000         1
         27     0.0000    0.0000    0.0000         3
         28     0.7023    0.7041    0.7032       392
         29     0.0000    0.0000    0.0000         1
         30     1.0000    0.1429    0.2500         7
         31     0.0000    0.0000    0.0000         6
         32     0.0000    0.0000    0.0000         5
         33     0.7632    0.8788    0.8169        33
         34     0.7945    0.8406    0.8169        69
         35     0.8152    0.9740    0.8876        77
         36     0.0000    0.0000    0.0000         6
         37     0.9487    0.8810    0.9136        42
         38     0.8235    0.8750    0.8485        64
         39     1.0000    0.1429    0.2500         7
         40     0.1905    0.1379    0.1600        29
         41     0.9186    0.9518    0.9349        83
         42     0.0000    0.0000    0.0000         4
         43     0.0000    0.0000    0.0000         6
         44     0.0000    0.0000    0.0000         8
         45     0.6937    0.8222    0.7525       135

avg / total     0.7452    0.7803    0.7579      2057

2020-05-11 21:53:09,888 - train_eval - INFO - dev_acc: 0.7802625182304327  dev_loss: 0.7722476
2020-05-11 21:53:09,888 - train_eval - INFO - -----------------------------------------------------------

2020-05-11 22:04:03,365 - train_eval - INFO - USING MODEL: bert_att, Using PTM: chinese_rbtl3_pytorch
2020-05-11 22:04:03,365 - train_eval - INFO - Batch_Size: 64, Using FL: False, Using DISCR: True, Using STLR: True
             precision    recall  f1-score   support

          0     0.8750    0.8750    0.8750        24
          1     0.0000    0.0000    0.0000         3
          2     0.9873    0.9512    0.9689        82
          3     0.3333    1.0000    0.5000         1
          4     0.9000    0.9783    0.9375        46
          5     0.9231    1.0000    0.9600        12
          6     0.9231    1.0000    0.9600        12
          7     0.6923    0.5294    0.6000        17
          8     0.7333    0.9167    0.8148        36
          9     0.9438    0.9333    0.9385        90
         10     0.6667    1.0000    0.8000         2
         11     0.8333    0.3333    0.4762        15
         12     0.6869    0.8000    0.7391        85
         13     1.0000    0.6667    0.8000         3
         14     1.0000    1.0000    1.0000         4
         15     0.8242    0.8568    0.8402       454
         16     1.0000    1.0000    1.0000        11
         17     1.0000    0.3000    0.4615        10
         18     0.8750    0.9459    0.9091        37
         19     1.0000    1.0000    1.0000         5
         20     1.0000    1.0000    1.0000         8
         21     1.0000    1.0000    1.0000         1
         22     1.0000    1.0000    1.0000         6
         24     0.8438    0.7941    0.8182       102
         25     1.0000    0.9231    0.9600        13
         26     0.0000    0.0000    0.0000         1
         27     1.0000    0.6667    0.8000         3
         28     0.7258    0.7092    0.7174       392
         29     0.0000    0.0000    0.0000         1
         30     0.4286    0.4286    0.4286         7
         31     0.8571    1.0000    0.9231         6
         32     1.0000    0.6000    0.7500         5
         33     0.8571    0.9091    0.8824        33
         34     0.8358    0.8116    0.8235        69
         35     0.9048    0.9870    0.9441        77
         36     1.0000    1.0000    1.0000         6
         37     0.9487    0.8810    0.9136        42
         38     0.8382    0.8906    0.8636        64
         39     1.0000    1.0000    1.0000         7
         40     0.4286    0.3103    0.3600        29
         41     1.0000    0.9759    0.9878        83
         42     1.0000    1.0000    1.0000         4
         43     0.6667    0.3333    0.4444         6
         44     0.8000    0.5000    0.6154         8
         45     0.7956    0.8074    0.8015       135

avg / total     0.8239    0.8250    0.8212      2057

2020-05-11 22:04:03,365 - train_eval - INFO - dev_acc: 0.8249878463782208  dev_loss: 0.5793522
2020-05-11 22:04:03,365 - train_eval - INFO - -----------------------------------------------------------
2020-05-11 23:54:42,499 - train_eval - INFO - USING MODEL: xlnet, Using PTM: chinese_xlnet_base_pytorch
2020-05-11 23:54:42,499 - train_eval - INFO - Batch_Size: 32, Using FL: True, Using DISCR: True, Using STLR: True
             precision    recall  f1-score   support

          0     0.9000    0.9310    0.9153        29
          1     0.3333    0.3333    0.3333         3
          2     0.9157    0.9870    0.9500        77
          3     0.0000    0.0000    0.0000         1
          4     0.8824    0.9783    0.9278        46
          5     0.0000    0.0000    0.0000         1
          6     0.0000    0.0000    0.0000         3
          7     0.4667    0.4667    0.4667        15
          8     0.7000    0.8750    0.7778        40
          9     0.9024    0.9737    0.9367        76
         10     1.0000    0.5000    0.6667         4
         11     0.8000    0.2857    0.4211        14
         12     0.6129    0.8736    0.7204        87
         13     0.5000    0.5000    0.5000         4
         15     0.8091    0.8345    0.8216       447
         16     0.0000    0.0000    0.0000         3
         17     0.0000    0.0000    0.0000         6
         18     0.9024    0.9737    0.9367        38
         20     0.0000    0.0000    0.0000         1
         21     0.0000    0.0000    0.0000         2
         22     0.8333    1.0000    0.9091         5
         24     0.7383    0.8495    0.7900        93
         25     0.9375    0.9375    0.9375        16
         26     0.0000    0.0000    0.0000         2
         28     0.7633    0.6418    0.6973       402
         29     0.0000    0.0000    0.0000         1
         30     0.6667    0.3333    0.4444         6
         31     0.0000    0.0000    0.0000         2
         32     0.0000    0.0000    0.0000         5
         33     0.6897    0.8000    0.7407        25
         34     0.7527    0.8537    0.8000        82
         35     0.8842    0.9545    0.9180        88
         36     0.0000    0.0000    0.0000         2
         37     0.8718    0.8500    0.8608        40
         38     0.8197    0.8197    0.8197        61
         40     0.2381    0.1724    0.2000        29
         41     0.9767    0.9545    0.9655        88
         42     1.0000    1.0000    1.0000         4
         43     1.0000    0.1250    0.2222         8
         44     0.0000    0.0000    0.0000         4
         45     0.7770    0.8214    0.7986       140

avg / total     0.7811    0.7925    0.7812      2000

2020-05-11 23:54:42,499 - train_eval - INFO - dev_acc: 0.7925  dev_loss: 0.42796385
2020-05-11 23:54:42,499 - train_eval - INFO - -----------------------------------------------------------

2020-05-12 00:14:47,493 - train_eval - INFO - USING MODEL: xlnet_CNN, Using PTM: chinese_xlnet_base_pytorch
2020-05-12 00:14:47,493 - train_eval - INFO - Batch_Size: 32, Using FL: True, Using DISCR: True, Using STLR: True
             precision    recall  f1-score   support

          0     0.8182    0.9310    0.8710        29
          1     0.0000    0.0000    0.0000         3
          2     0.8824    0.9740    0.9259        77
          3     0.0000    0.0000    0.0000         1
          4     0.8980    0.9565    0.9263        46
          5     0.0000    0.0000    0.0000         1
          6     1.0000    0.3333    0.5000         3
          7     0.4000    0.2667    0.3200        15
          8     0.6923    0.9000    0.7826        40
          9     0.8987    0.9342    0.9161        76
         10     0.4000    0.5000    0.4444         4
         11     0.7143    0.3571    0.4762        14
         12     0.6032    0.8736    0.7136        87
         13     0.5000    0.2500    0.3333         4
         15     0.8292    0.8255    0.8274       447
         16     1.0000    0.6667    0.8000         3
         17     0.0000    0.0000    0.0000         6
         18     0.9024    0.9737    0.9367        38
         20     0.0000    0.0000    0.0000         1
         21     0.0000    0.0000    0.0000         2
         22     1.0000    0.2000    0.3333         5
         24     0.8065    0.8065    0.8065        93
         25     0.9375    0.9375    0.9375        16
         26     0.5000    0.5000    0.5000         2
         28     0.7154    0.6567    0.6848       402
         29     0.0000    0.0000    0.0000         1
         30     0.5000    0.3333    0.4000         6
         31     0.0000    0.0000    0.0000         2
         32     0.0000    0.0000    0.0000         5
         33     0.7600    0.7600    0.7600        25
         34     0.7320    0.8659    0.7933        82
         35     0.8571    0.9545    0.9032        88
         36     0.0000    0.0000    0.0000         2
         37     0.8810    0.9250    0.9024        40
         38     0.8571    0.8852    0.8710        61
         40     0.2143    0.2069    0.2105        29
         41     0.9885    0.9773    0.9829        88
         42     0.6667    1.0000    0.8000         4
         43     0.5000    0.2500    0.3333         8
         44     0.0000    0.0000    0.0000         4
         45     0.8333    0.7500    0.7895       140

avg / total     0.7786    0.7880    0.7791      2000

2020-05-12 00:14:47,493 - train_eval - INFO - dev_acc: 0.788  dev_loss: 0.40601653
2020-05-12 00:14:47,493 - train_eval - INFO - -----------------------------------------------------------

2020-05-12 00:33:43,224 - train_eval - INFO - USING MODEL: xlnet_att, Using PTM: chinese_xlnet_base_pytorch
2020-05-12 00:33:43,224 - train_eval - INFO - Batch_Size: 32, Using FL: True, Using DISCR: True, Using STLR: True
             precision    recall  f1-score   support

          0     0.8438    0.9310    0.8852        29
          1     0.0000    0.0000    0.0000         3
          2     0.7170    0.9870    0.8306        77
          3     0.0000    0.0000    0.0000         1
          4     0.8333    0.9783    0.9000        46
          5     0.0000    0.0000    0.0000         1
          6     1.0000    1.0000    1.0000         3
          7     0.3889    0.4667    0.4242        15
          8     0.7447    0.8750    0.8046        40
          9     0.9211    0.9211    0.9211        76
         10     0.5000    0.5000    0.5000         4
         11     0.5000    0.3571    0.4167        14
         12     0.6460    0.8391    0.7300        87
         13     0.3333    0.2500    0.2857         4
         15     0.8239    0.8166    0.8202       447
         16     1.0000    0.6667    0.8000         3
         17     0.0000    0.0000    0.0000         6
         18     0.8409    0.9737    0.9024        38
         20     0.0000    0.0000    0.0000         1
         21     0.0000    0.0000    0.0000         2
         22     0.8333    1.0000    0.9091         5
         24     0.8090    0.7742    0.7912        93
         25     0.9375    0.9375    0.9375        16
         26     1.0000    0.5000    0.6667         2
         28     0.7109    0.5995    0.6505       402
         29     0.0000    0.0000    0.0000         1
         30     0.2500    0.3333    0.2857         6
         31     0.0000    0.0000    0.0000         2
         32     0.0000    0.0000    0.0000         5
         33     0.7917    0.7600    0.7755        25
         34     0.7907    0.8293    0.8095        82
         35     0.8763    0.9659    0.9189        88
         36     0.0000    0.0000    0.0000         2
         37     0.8605    0.9250    0.8916        40
         38     0.8333    0.9016    0.8661        61
         40     0.2979    0.4828    0.3684        29
         41     0.9878    0.9205    0.9529        88
         42     1.0000    1.0000    1.0000         4
         43     0.6667    0.2500    0.3636         8
         44     0.2500    0.2500    0.2500         4
         45     0.8110    0.7357    0.7715       140

avg / total     0.7733    0.7765    0.7708      2000

2020-05-12 00:33:43,224 - train_eval - INFO - dev_acc: 0.7765  dev_loss: 0.40734574
2020-05-12 00:33:43,224 - train_eval - INFO - -----------------------------------------------------------


2020-05-31 22:44:38,117 - train_eval - INFO - USING MODEL: bert_att, Using PTM: chinese_rbtl3_pytorch
2020-05-31 22:44:38,117 - train_eval - INFO - Batch_Size: 64, Using FL: True, Using DISCR: True, Using STLR: True
                                  precision    recall  f1-score   support

              Addictive Behavior     0.8696    0.8333    0.8511        24
                         Address     0.0000    0.0000    0.0000         3
                             Age     0.9873    0.9512    0.9689        82
                Alcohol Consumer     0.3333    1.0000    0.5000         1
             Allergy Intolerance     0.8824    0.9783    0.9278        46
                         Bedtime     0.9231    1.0000    0.9600        12
                  Blood Donation     0.9231    1.0000    0.9600        12
                        Capacity     0.6667    0.4706    0.5517        17
        Compliance with Protocol     0.6735    0.9167    0.7765        36
                         Consent     0.9348    0.9556    0.9451        90
                 Data Accessible     0.6667    1.0000    0.8000         2
                          Device     0.8000    0.2667    0.4000        15
                      Diagnostic     0.6600    0.7765    0.7135        85
                            Diet     0.6667    0.6667    0.6667         3
                    Disabilities     1.0000    1.0000    1.0000         4
                         Disease     0.8297    0.8480    0.8388       454
                       Education     1.0000    1.0000    1.0000        11
                       Encounter     1.0000    0.3000    0.4615        10
     Enrollment in other studies     0.8500    0.9189    0.8831        37
                   Ethical Audit     1.0000    1.0000    1.0000         5
                       Ethnicity     1.0000    1.0000    1.0000         8
                        Exercise     1.0000    1.0000    1.0000         1
                          Gender     1.0000    1.0000    1.0000         6
         Laboratory Examinations     0.8587    0.7745    0.8144       102
                 Life Expectancy     1.0000    0.9231    0.9600        13
                        Literacy     0.0000    0.0000    0.0000         1
                    Living Alone     1.0000    0.6667    0.8000         3
                        Multiple     0.7036    0.6964    0.7000       392
                 Neoplasm Status     0.0000    0.0000    0.0000         1
      Non-Neoplasm Disease Stage     0.3333    0.4286    0.3750         7
                         Nursing     0.7500    1.0000    0.8571         6
                    Oral related     1.0000    0.6000    0.7500         5
          Organ or Tissue Status     0.8235    0.8485    0.8358        33
Pharmaceutical Substance or Drug     0.8281    0.7681    0.7970        69
      Pregnancy-related Activity     0.8837    0.9870    0.9325        77
                 Receptor Status     1.0000    1.0000    1.0000         6
             Researcher Decision     0.9487    0.8810    0.9136        42
                 Risk Assessment     0.8406    0.9062    0.8722        64
              Sexual Orientation     1.0000    1.0000    1.0000         7
                            Sign     0.4444    0.2759    0.3404        29
                            Skip     1.0000    0.9759    0.9878        83
                  Smoking Status     1.0000    1.0000    1.0000         4
  Special Patient Characteristic     0.7500    0.5000    0.6000         6
                         Symptom     0.8000    0.5000    0.6154         8
              Therapy or Surgery     0.8000    0.8000    0.8000       135

                     avg / total     0.8159    0.8153    0.8117      2057

2020-05-31 22:44:38,117 - train_eval - INFO - dev_acc: 0.8152649489547885  dev_loss: 0.33276495
2020-05-31 22:44:38,117 - train_eval - INFO - -----------------------------------------------------------

